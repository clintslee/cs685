{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07baaed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1846bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    'calling',\n",
    "    'clapping',\n",
    "    'cycling',\n",
    "    'dancing',\n",
    "    'drinking',\n",
    "    'eating',\n",
    "    'fightning',\n",
    "    'hugging',\n",
    "    'laughing',\n",
    "    'listening_to_music',\n",
    "    'running',\n",
    "    'sitting',\n",
    "    'sleeping',\n",
    "    'texting',\n",
    "    'using_laptop'\n",
    "]\n",
    "\n",
    "# classify an image with the given model path\n",
    "def classify_image(batch_data, model, device):\n",
    "    image_list = []\n",
    "\n",
    "    # Need to test on batch size of 36 to match training size\n",
    "    for idx, row in batch_data.iterrows():\n",
    "      image_path = f\"/Users/clintlee/Development/vscode/CS685/data2/test/{row[1]}/{row[0]}\"\n",
    "\n",
    "      transform = transforms.Compose([\n",
    "          transforms.Resize((128, 128)),\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "      ])\n",
    "      \n",
    "      image = Image.open(image_path).convert('RGB')\n",
    "      image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "      image_list.append(image)\n",
    "\n",
    "    image_tensor = torch.cat(image_list, dim=0)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9263bcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset contains 1890 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/77/yjvjk5s92_gc6p2sqr10794w0000gn/T/ipykernel_86336/1017574126.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  image_path = f\"/Users/clintlee/Development/vscode/CS685/data2/test/{row[1]}/{row[0]}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1/52 (36/1890 images)\n",
      "Processed batch 2/52 (72/1890 images)\n",
      "Processed batch 3/52 (108/1890 images)\n",
      "Processed batch 4/52 (144/1890 images)\n",
      "Processed batch 5/52 (180/1890 images)\n",
      "Processed batch 6/52 (216/1890 images)\n",
      "Processed batch 7/52 (252/1890 images)\n",
      "Processed batch 8/52 (288/1890 images)\n",
      "Processed batch 9/52 (324/1890 images)\n",
      "Processed batch 10/52 (360/1890 images)\n",
      "Processed batch 11/52 (396/1890 images)\n",
      "Processed batch 12/52 (432/1890 images)\n",
      "Processed batch 13/52 (468/1890 images)\n",
      "Processed batch 14/52 (504/1890 images)\n",
      "Processed batch 15/52 (540/1890 images)\n",
      "Processed batch 16/52 (576/1890 images)\n",
      "Processed batch 17/52 (612/1890 images)\n",
      "Processed batch 18/52 (648/1890 images)\n",
      "Processed batch 19/52 (684/1890 images)\n",
      "Processed batch 20/52 (720/1890 images)\n",
      "Processed batch 21/52 (756/1890 images)\n",
      "Processed batch 22/52 (792/1890 images)\n",
      "Processed batch 23/52 (828/1890 images)\n",
      "Processed batch 24/52 (864/1890 images)\n",
      "Processed batch 25/52 (900/1890 images)\n",
      "Processed batch 26/52 (936/1890 images)\n",
      "Processed batch 27/52 (972/1890 images)\n",
      "Processed batch 28/52 (1008/1890 images)\n",
      "Processed batch 29/52 (1044/1890 images)\n",
      "Processed batch 30/52 (1080/1890 images)\n",
      "Processed batch 31/52 (1116/1890 images)\n",
      "Processed batch 32/52 (1152/1890 images)\n",
      "Processed batch 33/52 (1188/1890 images)\n",
      "Processed batch 34/52 (1224/1890 images)\n",
      "Processed batch 35/52 (1260/1890 images)\n",
      "Processed batch 36/52 (1296/1890 images)\n",
      "Processed batch 37/52 (1332/1890 images)\n",
      "Processed batch 38/52 (1368/1890 images)\n",
      "Processed batch 39/52 (1404/1890 images)\n",
      "Processed batch 40/52 (1440/1890 images)\n",
      "Processed batch 41/52 (1476/1890 images)\n",
      "Processed batch 42/52 (1512/1890 images)\n",
      "Processed batch 43/52 (1548/1890 images)\n",
      "Processed batch 44/52 (1584/1890 images)\n",
      "Processed batch 45/52 (1620/1890 images)\n",
      "Processed batch 46/52 (1656/1890 images)\n",
      "Processed batch 47/52 (1692/1890 images)\n",
      "Processed batch 48/52 (1728/1890 images)\n",
      "Processed batch 49/52 (1764/1890 images)\n",
      "Processed batch 50/52 (1800/1890 images)\n",
      "Processed batch 51/52 (1836/1890 images)\n",
      "Processed batch 52/52 (1872/1890 images)\n",
      "Note: 18 images remain unprocessed as they don't form a complete batch of 36\n",
      "\n",
      "Accuracy: 82.53% (1545/1872)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "model = models.convnext_base(weights='DEFAULT').to(device)\n",
    "    \n",
    "in_features = model.classifier[2].in_features\n",
    "num_classes = 15\n",
    "\n",
    "# Modify classifier\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.LayerNorm(( 36,1024,1,1)), \n",
    "    nn.Flatten(1),\n",
    "    nn.Linear(in_features, num_classes)\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"/Users/clintlee/Development/vscode/CS685/models/convnext/convnext_model.pth\", map_location=torch.device(\"cpu\")))\n",
    "\n",
    "\n",
    "# Read the CSV file\n",
    "# Using absolute path similar to the model path\n",
    "test_data = pd.read_csv(\"/Users/clintlee/Development/vscode/CS685/data2/test/test_labels.csv\")\n",
    "print(f\"Test dataset contains {len(test_data)} images\")\n",
    "\n",
    "# Assuming first column is filename and third is the true label\n",
    "# Adjust these if your CSV has different structure\n",
    "filename_col = 0\n",
    "folder_col = 1\n",
    "label_col = 2\n",
    "\n",
    "# Process images and compute accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "num_batches = len(test_data) / 36\n",
    "\n",
    "\n",
    "# Process images in batches of 36\n",
    "batch_size = 36\n",
    "num_complete_batches = int(len(test_data) // batch_size)\n",
    "\n",
    "for batch_idx in range(num_complete_batches):\n",
    "    try:\n",
    "        # Get corresponding true labels from test_data\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx + 1) * batch_size\n",
    "        batch_data = test_data.iloc[start_idx:end_idx]\n",
    "        true_labels = batch_data.iloc[:, label_col].tolist()\n",
    "\n",
    "        # Get predictions for a batch of 36 images\n",
    "        predicted_labels = classify_image(batch_data, model, device)\n",
    "        \n",
    "        # Compare predictions with true labels\n",
    "        for idx, (pred, true) in enumerate(zip(predicted_labels, true_labels)):\n",
    "            if pred.item() == true:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        \n",
    "        # Print progress update\n",
    "        print(f\"Processed batch {batch_idx+1}/{num_complete_batches} ({end_idx}/{len(test_data)} images)\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {batch_idx+1}: {e}\")\n",
    "\n",
    "# Handle remaining images if any (less than a batch)\n",
    "remaining = len(test_data) % batch_size\n",
    "if remaining > 0:\n",
    "    print(f\"Note: {remaining} images remain unprocessed as they don't form a complete batch of 36\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}% ({correct}/{total})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
